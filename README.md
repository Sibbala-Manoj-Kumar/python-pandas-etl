# ğŸš€ Customer Orders ETL Pipeline  
### Python â€¢ Pandas â€¢ Data Engineering Fundamentals

<p align="center">
  <img src="assets/etl_pipeline.gif" width="700"/>
</p>

---

## ğŸ§  Project Overview

This project demonstrates a **production-style ETL pipeline** built using **Python and Pandas**.  
It transforms raw customer and order data into an **analytics-ready dataset**, following best practices used in real-world data engineering pipelines.

The logic and structure closely resemble workflows orchestrated using **Airflow**, processed using **Dataproc**, and consumed in **BigQuery**.

---

## ğŸ¯ Business Problem

Given raw datasets:
- ğŸ‘¤ Customers
- ğŸ§¾ Orders  

The objective is to:
- Clean and standardize raw data
- Handle missing values safely
- Filter valid transactions
- Aggregate key business metrics
- Enrich data using customer master information
- Generate a final dataset ready for analytics and reporting

---

## ğŸ› ï¸ ETL Pipeline Flow (Logical Steps)

# ğŸš€ Customer Orders ETL Pipeline  
### Python â€¢ Pandas â€¢ Data Engineering Fundamentals

<p align="center">
  <img src="assets/etl_pipeline.gif" width="700"/>
</p>

---

## ğŸ§  Project Overview

This project demonstrates a **production-style ETL pipeline** built using **Python and Pandas**.  
It transforms raw customer and order data into an **analytics-ready dataset**, following best practices used in real-world data engineering pipelines.

The logic and structure closely resemble workflows orchestrated using **Airflow**, processed using **Dataproc**, and consumed in **BigQuery**.

---

## ğŸ¯ Business Problem

Given raw datasets:
- ğŸ‘¤ Customers
- ğŸ§¾ Orders  

The objective is to:
- Clean and standardize raw data
- Handle missing values safely
- Filter valid transactions
- Aggregate key business metrics
- Enrich data using customer master information
- Generate a final dataset ready for analytics and reporting

---

## ğŸ› ï¸ ETL Pipeline Flow (Logical Steps)

ğŸ“‚ Raw CSV Files
â”‚
â–¼
ğŸ“¥ Read Data (Pandas)
â”‚
â–¼
ğŸ§¹ Clean Column Names
â”‚
â–¼
ğŸš¨ Handle Missing Values
â”‚
â–¼
âœ… Filter Completed Orders
â”‚
â–¼
ğŸ“Š Aggregate Order Amounts
â”‚
â–¼
ğŸ”— Join Customer Master Data
â”‚
â–¼
ğŸ“¤ Final Analytics Output (CSV)


---

## ğŸ–¼ï¸ Visual Pipeline Diagram

<p align="center">
  <img src="assets/etl_pipeline.png" width="700"/>
</p>

> ğŸ’¡ This pipeline follows the same logical structure used in Airflow-orchestrated GCP data pipelines.

---

## ğŸ“ Project Structure

python_pandas_etl/
â”‚
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ etl_pipeline.png
â”‚ â””â”€â”€ etl_pipeline.gif
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ customers.csv
â”‚ â””â”€â”€ orders.csv
â”‚
â”œâ”€â”€ output/
â”‚ â””â”€â”€ customer_order_summary.csv
â”‚
â”œâ”€â”€ etl.py # Step-by-step learning version
â”œâ”€â”€ final_etl.py # Production-style modular ETL
â””â”€â”€ README.md


---

## ğŸ“Š Final Output Schema

| Column | Description |
|------|------------|
| customer_id | Unique customer identifier |
| customer_name | Customer name |
| city | Customer city |
| total_order_amount | Total completed order value |

ğŸ“„ Output file:
output/customer_order_summary.csv


---

## ğŸ§© Key Transformations

### ğŸ§¹ Data Cleaning
- Standardized column names (lowercase, underscores)
- Ensured SQL / BigQuery compatibility

### ğŸš¨ Data Quality Handling
- Identified missing values in order data
- Applied business rules (`order_amount = 0`)

### ğŸ“Š Aggregation
- Grouped orders by customer
- Calculated total completed order value

### ğŸ”— Data Enrichment
- Joined aggregated order data with customer master data

---

## ğŸ§  Engineering Design Principles

- Modular Python functions for each ETL stage
- Clear pipeline orchestration via `main()`
- Production-style design aligned with Airflow task patterns

---



## ğŸŒ± Future Enhancements

- ğŸ”„ Convert pipeline to **PySpark** for Dataproc
- â˜ï¸ Load output directly into **BigQuery**
- ğŸ•’ Orchestrate pipeline using **Apache Airflow**

---

â­ If you find this project useful, feel free to star the repository!
